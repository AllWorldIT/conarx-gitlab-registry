.middleware:storage: &middleware-storage
  extends: .go-version-matrix
  stage: integration

middleware:storage-googlecdn:
  <<: *middleware-storage
  variables:
    REGISTRY_STORAGE_GCS_BUCKET: $CDN_GCS_BUCKET
    REGISTRY_MIDDLEWARE_STORAGE_GOOGLECDN_BASEURL: $CDN_BASEURL
    REGISTRY_MIDDLEWARE_STORAGE_GOOGLECDN_KEYNAME: $CDN_KEYNAME
    PACKAGE: github.com/docker/distribution/registry/storage/driver/middleware/googlecdn
  before_script:
    - export GOOGLE_APPLICATION_CREDENTIALS="$CDN_CREDENTIALS"
    - export REGISTRY_MIDDLEWARE_STORAGE_GOOGLECDN_PRIVATEKEY="$CDN_PRIVATEKEY"
  script:
    - $GO_TEST -v -coverprofile=coverage.out -tags=integration

.storage-driver-test: &storage-driver-test
  extends: .go-version-matrix
  stage: integration
  variables: &storage-driver-variables
    TEST_TIMEOUT: "30m"
  script: $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE

filesystem:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    PACKAGE: 'github.com/docker/distribution/registry/storage/driver/filesystem'

inmemory:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    PACKAGE: 'github.com/docker/distribution/registry/storage/driver/inmemory'
    # Always run short tests for in-memory driver or we might run out of memory
    # and cause a flaky test https://gitlab.com/gitlab-org/container-registry/-/issues/1177
  script: $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE -test.short

s3:minio:
  <<: *storage-driver-test
  parallel:
    matrix:
      # Regular combinations
      - GO_VERSION: [ "1.23", "1.24" ]
        S3_DRIVER_VERSION: [ "s3", "s3_v2" ]
  rules:
    - if: $CI_COMMIT_REF_NAME != $CI_DEFAULT_BRANCH
      when: on_success
  variables:
    <<: *storage-driver-variables
    MINIO_ACCESS_KEY: "AKIAIOSFODNN7EXAMPLE"
    MINIO_SECRET_KEY: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
    REGION_ENDPOINT: "http://minio:9000"
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/s3-aws"
    # NOTE(prozlach): see docs/storage-drivers/s3_v2.md#minio for explanation why:
    S3_CHECKSUM_DISABLED: "true"
  services:
    - name: minio/minio:latest
      alias: "minio"
      command: ["server", "/data"]
  before_script:
    # Download the minio client
    - wget --no-verbose https://dl.min.io/client/mc/release/linux-amd64/mc
    - chmod u+x ./mc
    # Configure the minio client to use the local minio service rather than play.minio.io
    - |
      for i in `env | grep -E 'S3|AWS' | cut -d\= -f1`; do unset $i; done;
      export S3_BUCKET="test-bucket"

      ./mc config host add s3v4 $REGION_ENDPOINT $MINIO_ACCESS_KEY $MINIO_SECRET_KEY --api S3v4
      ./mc mb s3v4/$S3_BUCKET
  script:
    # NOTE(prozlach): Project and group credentials take precedence over job
    # credentials as per https://docs.gitlab.com/ci/variables/#cicd-variable-precedence
    # so we need clean up any env vars and set our own before we run the tests.
    - |
      for i in `env | grep -E 'S3|AWS' | cut -d\= -f1`; do unset $i; done;
      export AWS_ACCESS_KEY=$MINIO_ACCESS_KEY
      export AWS_SECRET_KEY=$MINIO_SECRET_KEY
      export AWS_REGION="us-east-2"
      export S3_BUCKET="test-bucket"
      export S3_ENCRYPT="false"
      $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE

# NOTE(prozlach): S3 bucket used in tests has an auto-cleanup policy set
# - all blobs older than 24h will be deleted, so even if CI task fails, there
# is no risk that we will keep being billed for the storage indefinatelly.
# NOTE(prozlach): Instructions on how to set-up custom runner are in file
# `docs/custom_runners.md`
s3:aws:
  <<: *storage-driver-test
  parallel:
    matrix:
      # Regular combinations
      - GO_VERSION: [ "1.23", "1.24" ]
        S3_DRIVER_VERSION: [ "s3", "s3_v2" ]
        S3_AUTH_MODE: ["key_auth"]
      - GO_VERSION: [ "1.23", "1.24" ]
        S3_DRIVER_VERSION: [ "s3_v2" ]
        S3_AUTH_MODE: ["instance_auth"]
  rules:
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH
      when: on_success
  variables:
    <<: *storage-driver-variables
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/s3-aws"
  tags:
    # NOTE(prozlach): run on a custom runner, that runs on an AWS VM which has
    # managed credentials set up for the bucket that CI variables point to.
    # Other variants run here as well in order to save $$ on bandwith costs.
    - s3-managed_identity_auth
  script:
    # NOTE(prozlach): In case when we test managed credentials variant, we need
    # to make sure that AWS SDK will not try to auth with creds from
    # environment and instead tries to obtain managed credentials from the VM
    # itself.
    - |
      if [[ "$S3_AUTH_MODE" == "instance_auth" ]]; then
        echo "Unsetting key credentials"
        unset AWS_ACCESS_KEY
        unset AWS_SECRET_KEY
        unset AWS_ACCESS_KEY_ID
        unset AWS_SECRET_ACCESS_KEY
      fi
      $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE

.if-fork-merge-request: &if-fork-merge-request
  if: '($CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train") && $CI_PROJECT_NAMESPACE !~ /^gitlab(-org)?($|\/)/'

gcs:key_creds:
  <<: *storage-driver-test
  parallel:
    matrix:
      - GO_VERSION: [ "1.23", "1.24" ]
        REGISTRY_GCS_DRIVER: [ "current", "next" ]
  rules:
    - <<: *if-fork-merge-request
      when: never
    - changes:
        - registry/storage/driver/gcs/*
        - registry/storage/driver/gcs/testdata/*
        - registry/storage/driver/testsuites/*
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH
  variables:
    <<: *storage-driver-variables
    REGISTRY_STORAGE_GCS_BUCKET: $GCS_BUCKET
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/gcs"
    TEST_TIMEOUT: "35m"
  before_script:
    - export GOOGLE_APPLICATION_CREDENTIALS="$CDN_CREDENTIALS"

gcs:instance_creds:
  <<: *storage-driver-test
  parallel:
    matrix:
      - GO_VERSION: [ "1.23", "1.24" ]
        # Only supported on `next` driver:
        REGISTRY_GCS_DRIVER: [ "next" ]
 # Do not run in forked projects, as we are running on custom runner with
 # instance-level credentials
  rules:
    - <<: *if-fork-merge-request
      when: never
    - changes:
        - registry/storage/driver/gcs/*
        - registry/storage/driver/gcs/testdata/*
        - registry/storage/driver/testsuites/*
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH
  tags:
    # NOTE(prozlach): run on a custom runner, that runs on an GCS VM which has
    # managed credentials set up for the bucket that CI variables point to.
    # Other variants do not need to run here as our default runners run in
    # Google Cloud anyway.
    - gcs-managed_identity_auth
  variables:
    <<: *storage-driver-variables
    REGISTRY_STORAGE_GCS_BUCKET: $GCS_BUCKET
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/gcs"
    TEST_TIMEOUT: "35m"

# NOTE(prozlach): Azure storage container used in tests has an auto-cleanup policy set
# - all blobs older than 24h will be deleted, so even if CI task fails, there
# is no risk that we will keep being billed for the storage indefinatelly.
# NOTE(prozlach): Instructions on how to set-up custom runner are in file
# `docs/custom_runners.md`
azure:
  <<: *storage-driver-test
  parallel:
    matrix:
      # Regular combinations
      - GO_VERSION: [ "1.23", "1.24" ]
        AZURE_DRIVER_VERSION: [ "azure", "azure_v2" ]
        AZURE_CREDENTIALS_TYPE: [ "shared_key" ]
      - GO_VERSION: [ "1.23", "1.24" ]
        AZURE_DRIVER_VERSION: [ "azure_v2" ]
        AZURE_CREDENTIALS_TYPE: [ "client_secret", "default_credentials" ]
 # Do not run in forked projects, as we are running on custom runner with
 # instance-level credentials
  rules:
    - <<: *if-fork-merge-request
      when: never
    # Cover the case when there is an MR merged to the default branch:
    # https://docs.gitlab.com/ci/yaml/#ruleschanges
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH && $AZURE_DRIVER_VERSION == "azure_v2"
      allow_failure: false
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH && $AZURE_DRIVER_VERSION == "azure"
      allow_failure: true
    - if: $AZURE_DRIVER_VERSION == "azure_v2"
      changes:
        - registry/storage/driver/azure/*
        - registry/storage/driver/azure/common/*
        - registry/storage/driver/azure/v2/*
        - registry/storage/driver/testsuites/*
      allow_failure: false
    - if: $AZURE_DRIVER_VERSION == "azure"
      changes:
        - registry/storage/driver/azure/*
        - registry/storage/driver/azure/common/*
        - registry/storage/driver/azure/v1/*
        - registry/storage/driver/testsuites/*
      allow_failure: true
  variables:
    <<: *storage-driver-variables
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/azure/..."
    AZURE_DRIVER_VERSION: $AZURE_DRIVER_VERSION
    AZURE_CREDENTIALS_TYPE: $AZURE_CREDENTIALS_TYPE
    # NOTE(prozlach): Code supports `AZURE_DEBUGLOG` environment variable which
    # can be toggled in the CI via CI enviroment variables for debugging
    # if/when needed. It is currently set to `false`, set it to `true` to
    # enable debug logging.
  tags:
    # NOTE(prozlach): run on a custom runner, that runs on Azure VM which has
    # managed credentials set up for the storage account and container that CI
    # variables define. Other variants run here as well in order to save $$ on
    # bandwith costs.
    - azure-managed_identity_auth
  script:
    # NOTE(prozlach): In case when we test managed credentials variant, we need
    # to make sure that Azure SDK will not try to auth with creds from
    # environment and instead tries to obtain managed credentials from the VM
    # itself.
    - |
      if [[ "$AZURE_CREDENTIALS_TYPE" == "default_credentials" ]]; then
        echo "Unsetting key credentials"
        unset AZURE_ACCOUNT_KEY
        unset AZURE_TENANT_ID
        unset AZURE_CLIENT_ID
        unset AZURE_CLIENT_SECRET
      fi
      $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE

api:
  extends: .go-version-matrix
  stage: integration
  variables:
    TAGS: 'integration,handlers_test'
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS

api:conformance:
  extends: .go-version-matrix
  stage: integration
  variables:
    TAGS: 'integration,api_conformance_test'
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS

.database: &database
  extends:
    - .go-test
    - .go-pg-version-matrix
  stage: integration
  variables: &database-variables
    FF_NETWORK_PER_BUILD: 1
    POSTGRES_PASSWORD: "secret"
    POSTGRES_DB: "registry_test"
    REGISTRY_DATABASE_ENABLED: "true"
    REGISTRY_DATABASE_HOST: "db"
    REGISTRY_DATABASE_PORT: "5432"
    REGISTRY_DATABASE_USER: "postgres"
    REGISTRY_DATABASE_PASSWORD: "secret"
    REGISTRY_DATABASE_DBNAME: "registry_test"
    REGISTRY_DATABASE_SSLMODE: "disable"
    TAGS: 'integration'
  services:
    - name: postgres:${PG_VERSION}-alpine
      alias: "db"
  script: $GO_TEST -v -timeout=25m -coverprofile=coverage.out -tags=$TAGS

api:online-gc:
  <<: *database
  variables:
    <<: *database-variables
    TAGS: 'integration,online_gc_test'
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS -run=OnlineGC

database:migrations:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/datastore/migrations'

database:datastore:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/datastore'

database:api:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TAGS: integration,handlers_test

database:api-conformance:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TAGS: 'integration,api_conformance_test'
  script: $GO_TEST -v -timeout=25m -tags=$TAGS

database:api-gitlab:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TAGS: 'integration,api_gitlab_test'
  script: $GO_TEST -v -timeout=25m -tags=$TAGS

# Tests that simulate adverse network conditions/errors between the registry and its database.
database:api-fault-tolerance:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TOXIPROXY_HOST: 'toxiproxy'
    TOXIPROXY_PORT: '8474'
    TAGS: 'integration,toxiproxy'
  services:
    # `services` are not extended, so we have to redeclare `postgres` here.
    - name: postgres:${PG_VERSION}-alpine
      alias: "db"
    - name: shopify/toxiproxy
      alias: "toxiproxy"
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS -run ^TestDBFaultTolerance

database:background-migrations:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/bbm'
    TAGS: 'integration'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS

.database-load-balancing: &database-load-balancing
  <<: *database
  variables: &database-load-balancing-variables
    <<: *database-variables
    POSTGRESQL_PASSWORD: "secret"
    POSTGRESQL_DATABASE: "registry_test"
    POSTGRESQL_REPLICATION_USER: "repluser"
    POSTGRESQL_REPLICATION_PASSWORD: "replpassword"
    POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    REGISTRY_DATABASE_HOST: "primary"
    REGISTRY_DATABASE_LOADBALANCING_ENABLED: "true"
    REGISTRY_REDIS_LOADBALANCING_ENABLED:  "true"
    REGISTRY_REDIS_LOADBALANCING_ADDR: "redis:6379"
    PACKAGE: "github.com/docker/distribution/registry/handlers"
    TAGS: "integration,handlers_test,api_gitlab_test,api_conformance_test"
  services:
    - name: redis:alpine
      alias: "redis"
    - name: bitnami/postgresql:${PG_VERSION}
      alias: "primary"
      variables:
        POSTGRESQL_REPLICATION_MODE: "master"
        POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    - name: bitnami/postgresql:${PG_VERSION}
      alias: "replica1"
      variables:
        POSTGRESQL_REPLICATION_MODE: "slave"
        POSTGRESQL_MASTER_HOST: "primary"
        POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    - name: bitnami/postgresql:${PG_VERSION}
      alias: "replica2"
      variables:
        POSTGRESQL_REPLICATION_MODE: "slave"
        POSTGRESQL_MASTER_HOST: "primary"
        POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    # not needed for all scenarios but avoids having to declare all services in each as `services` can't be extended
    - name: registry.gitlab.com/gitlab-org/container-registry/test-dns-server:28d4a455
      alias: "test-dns-server"
      variables:
        DNS_SERVER_SRV_RECORD: "replica.registry-db.service.consul"
        DNS_SERVER_REPLY_HOSTS: "replica1,replica2"
        DNS_SERVER_REPLY_PORT: "5432"
        DNS_SERVER_LISTEN_PORT: "8600"
  script: $GO_TEST -v -timeout=35m -coverprofile=coverage.out -tags=$TAGS

database:api-load-balancing-hosts:
  <<: *database-load-balancing
  variables:
    <<: *database-load-balancing-variables
    REGISTRY_DATABASE_LOADBALANCING_HOSTS: "replica1,replica2"

database:api-load-balancing-discovery:
  <<: *database-load-balancing
  variables:
    <<: *database-load-balancing-variables
    REGISTRY_DATABASE_LOADBALANCING_RECORD: "replica.registry-db.service.consul"
    REGISTRY_DATABASE_LOADBALANCING_NAMESERVER: "test-dns-server"
    REGISTRY_DATABASE_LOADBALANCING_PORT: "8600"

# TODO: remove fallback to `redis.cache` once we're making use of `redis.loadbalancing` in production:
# https://gitlab.com/gitlab-org/container-registry/-/issues/1535
database:api-load-balancing-discovery-cache-fallback:
  <<: *database-load-balancing
  variables:
    <<: *database-load-balancing-variables
    REGISTRY_REDIS_CACHE_ENABLED: "true"
    REGISTRY_REDIS_CACHE_ADDR: "redis:6379"
    REGISTRY_DATABASE_LOADBALANCING_RECORD: "replica.registry-db.service.consul"
    REGISTRY_DATABASE_LOADBALANCING_NAMESERVER: "test-dns-server"
    REGISTRY_DATABASE_LOADBALANCING_PORT: "8600"
  before_script:
    - unset REGISTRY_REDIS_LOADBALANCING_ENABLED
    - unset REGISTRY_REDIS_LOADBALANCING_ADDR

.cache:redis: &cache-redis
  extends: .go-version-matrix
  stage: integration
  variables: &cache-redis-variables
    REDIS_ADDR: "redis:6379"
    PACKAGE: "github.com/docker/distribution/registry/storage/cache/redis"
  services:
    - name: redis:alpine
      alias: "redis"
  script: $GO_TEST -v -coverprofile=coverage.out -tags=integration

cache:redis:
  extends: .cache:redis

cache:redis-auth:
  <<: *cache-redis
  variables:
    <<: *cache-redis-variables
    # create a Docker network per build so that services can talk with each other
    FF_NETWORK_PER_BUILD: 1
    REDIS_USERNAME: "my-redis-user"
    REDIS_PASSWORD: "my-redis-pass"
  services:
    - name: redis:alpine
      alias: "redis"
      command:
        - /bin/sh
        - -c
        - |
          echo "Starting Redis..."
          cat <<EOF > /etc/redis.conf
          user default off
          user ${REDIS_USERNAME} on >${REDIS_PASSWORD} allcommands allkeys
          EOF
          redis-server /etc/redis.conf

cache:redis-sentinel:
  <<: *cache-redis
  variables:
    <<: *cache-redis-variables
    # create a Docker network per build so that services can talk with each other
    FF_NETWORK_PER_BUILD: 1
    # config for redis-sentinel
    REDIS_MASTER_HOST: "redis"
    REDIS_MASTER_SET: "main-redis"
    # config for app
    REDIS_ADDR: "redis-sentinel:26379"
    REDIS_MAIN_NAME: "main-redis"
  services:
    - name: redis:alpine
      alias: "redis"
    - name: bitnami/redis-sentinel
      alias: "redis-sentinel"

cache:redis-sentinel-auth:
  <<: *cache-redis
  variables:
    <<: *cache-redis-variables
    # create a Docker network per build so that services can talk with each other
    FF_NETWORK_PER_BUILD: 1
    # config for redis-sentinel
    REDIS_MASTER_HOST: "redis"
    REDIS_MASTER_SET: "main-redis"
    # config for app
    REDIS_ADDR: "redis-sentinel:26379"
    REDIS_MAIN_NAME: "main-redis"
    REDIS_SENTINEL_USERNAME: "my-sentinel-user"
    REDIS_SENTINEL_PASSWORD: "my-sentinel-pass"
  services:
    - name: redis:alpine
      alias: "redis"
    - name: bitnami/redis-sentinel
      alias: "redis-sentinel"
      command:
        - /bin/sh
        - -c
        - |
          echo "Starting Redis Sentinel..."
          cat <<EOF > /opt/bitnami/redis-sentinel/etc/sentinel.conf
          user default off
          user ${REDIS_SENTINEL_USERNAME} on >${REDIS_SENTINEL_PASSWORD} +@all
          sentinel monitor ${REDIS_MAIN_NAME} ${REDIS_MASTER_HOST} 6379 2
          sentinel resolve-hostnames yes
          EOF
          redis-sentinel /opt/bitnami/redis-sentinel/etc/sentinel.conf

base-driver:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/base"

# Temporary integration tests for modified copy of redis_rate
# See https://gitlab.com/gitlab-org/container-registry/-/issues/1527.
redis:rate:
  extends: .go-version-matrix
  rules:
    - when: on_success
      changes:
        - internal/redis_rate/*
  stage: integration
  variables:
    REDIS_ADDR: "redis:6379"
    PACKAGE: "github.com/docker/distribution/internal/redis_rate"
  services:
    - name: redis:alpine
      alias: "redis"
  script: $GO_TEST -v -coverprofile=coverage.out -tags=integration

# cli:schema-migration-dependency is an integration test suite that verifies the dependency resolver for post/pre-deployment schema migrations.
cli:schema-migration-dependency:
  extends:
    - .go-test
  tags:
    - gitlab-org-docker
  services:
    - name: docker:27.2.0-dind
      alias: docker
  stage: integration
  variables:
    DOCKER_HOST: "tcp://docker:2375"
    TAGS: 'integration,cli_test'
    PACKAGE: 'github.com/docker/distribution/registry'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS
