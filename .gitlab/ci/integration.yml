.middleware:storage: &middleware-storage
  extends: .go-version-matrix
  stage: integration

middleware:storage-googlecdn:
  <<: *middleware-storage
  variables:
    REGISTRY_STORAGE_GCS_BUCKET: $CDN_GCS_BUCKET
    REGISTRY_MIDDLEWARE_STORAGE_GOOGLECDN_BASEURL: $CDN_BASEURL
    REGISTRY_MIDDLEWARE_STORAGE_GOOGLECDN_KEYNAME: $CDN_KEYNAME
    PACKAGE: github.com/docker/distribution/registry/storage/driver/middleware/googlecdn
  before_script:
    - export GOOGLE_APPLICATION_CREDENTIALS="$CDN_CREDENTIALS"
    - export REGISTRY_MIDDLEWARE_STORAGE_GOOGLECDN_PRIVATEKEY="$CDN_PRIVATEKEY"
  script:
    - $GO_TEST -v -coverprofile=coverage.out -tags=include_gcs,integration

.storage-driver-test: &storage-driver-test
  extends: .go-version-matrix
  stage: integration
  variables: &storage-driver-variables
    TEST_TIMEOUT: "30m"
  script: $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE

filesystem:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    PACKAGE: 'github.com/docker/distribution/registry/storage/driver/filesystem'

inmemory:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    PACKAGE: 'github.com/docker/distribution/registry/storage/driver/inmemory'
    # Always run short tests for in-memory driver or we might run out of memory
    # and cause a flaky test https://gitlab.com/gitlab-org/container-registry/-/issues/1177
  script: $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE -test.short

s3-aws:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    AWS_ACCESS_KEY: "AKIAIOSFODNN7EXAMPLE"
    AWS_SECRET_KEY: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
    MINIO_ACCESS_KEY: $AWS_ACCESS_KEY
    MINIO_SECRET_KEY: $AWS_SECRET_KEY
    REGION_ENDPOINT: "http://minio:9000"
    AWS_REGION: "us-east-2"
    S3_BUCKET: "test-bucket"
    S3_ENCRYPT: "false"
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/s3-aws"
  services:
    - name: minio/minio:latest
      alias: "minio"
      command: ["server", "/data"]
  before_script:
    # Download the minio client
    - wget --no-verbose https://dl.min.io/client/mc/release/linux-amd64/mc
    - chmod u+x ./mc
    # Configure the minio client to use the local minio service rather than play.minio.io
    - ./mc config host add s3v4 $REGION_ENDPOINT $AWS_ACCESS_KEY $AWS_SECRET_KEY --api S3v4
    - ./mc mb s3v4/$S3_BUCKET

gcs:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    REGISTRY_STORAGE_GCS_BUCKET: $GCS_BUCKET
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/gcs"
    TEST_TIMEOUT: "35m"
  before_script:
    - export GOOGLE_APPLICATION_CREDENTIALS="$CDN_CREDENTIALS"

.if-fork-merge-request: &if-fork-merge-request
  if: '($CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_EVENT_TYPE != "merge_train") && $CI_PROJECT_NAMESPACE !~ /^gitlab(-org)?($|\/)/'

# NOTE(prozlach): Azure storage container used in tests has an auto-cleanup policy set
# - all blobs older than 24h will be deleted, so even if CI task fails, there
# is no risk that we will keep being billed for the storage indefinatelly.
azure:default-runner:
  <<: *storage-driver-test
  parallel:
    matrix:
      # Regular combinations
      - GO_VERSION: [ "1.23", "1.24" ]
        AZURE_DRIVER_VERSION: [ "azure", "azure_v2" ]
        AZURE_CREDENTIALS_TYPE: [ "shared_key" ]
      - GO_VERSION: [ "1.23", "1.24" ]
        AZURE_DRIVER_VERSION: [ "azure_v2" ]
        AZURE_CREDENTIALS_TYPE: [ "client_secret" ]
  variables:
    <<: *storage-driver-variables
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/azure/..."
    AZURE_DRIVER_VERSION: $AZURE_DRIVER_VERSION
    AZURE_CREDENTIALS_TYPE: $AZURE_CREDENTIALS_TYPE
    # NOTE(prozlach): Code supports `AZURE_DEBUGLOG` environment variable which
    # can be toggled in the CI via CI enviroment variables for debugging
    # if/when needed. It is currently set to `false`, set it to `true` to
    # enable debug logging.
    # NOTE(prozlach): From what I noticed, if the tests do not finish within 45
    # minutes, they will not finish in 60 minutes either. A lot depends on the
    # latency between the Gitlab runner and azure store account. Moving Azure
    # storage closer to Gitlab runners (i.e. us-east Azure zone) decreased run
    # time from ~40m to around 9m. 
  # TODO: remove allow_failure once the test setup is fixed
  # https://gitlab.com/gitlab-org/container-registry/-/issues/1478
  allow_failure: true

# NOTE(prozlach): Do not run all azure jobs on the azure runner as it does not
# have enough capacity and is not secure enough to be exposed to shared_key
# credentials.
# NOTE(prozlach): Access credentials for the VM are stored in 1Password, entry
# `container-registry-cirunner`.
# NOTE(prozlach): Setting up custom runner follows the standard steps
# documented for setting up custom gitlab runner with few extra steps:
# * the host must be assigned managed identy access with level Data Contributor
# to the blob storage account we use for testing
# * the runner must be configured to use docker executor in host network mode
# * the concurency level for the runner should be set to at least 6
# * the runner should have at least 4 vCPU and 16GiB RAM
# * running untagged jobs on this runner must be disabled
# * runner must be tagged with `azure-managed_identity_auth` tag
azure:managed-identity:
  <<: *storage-driver-test
  parallel:
    matrix:
      # Managed identity combinations
      - GO_VERSION: [ "1.23", "1.24" ]
        AZURE_DRIVER_VERSION: [ "azure_v2" ]
        AZURE_CREDENTIALS_TYPE: [ "default_credentials" ]
  # Do not run in forked projects, as they can't use the custom runner:
  rules:
    - <<: *if-fork-merge-request
      when: never
    - when: on_success
  variables:
    <<: *storage-driver-variables
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/azure/..."
    AZURE_DRIVER_VERSION: $AZURE_DRIVER_VERSION
    AZURE_CREDENTIALS_TYPE: $AZURE_CREDENTIALS_TYPE
    # NOTE(prozlach): Code supports `AZURE_DEBUGLOG` environment variable which
    # can be toggled in the CI via CI enviroment variables for debugging
    # if/when needed. It is currently set to `false`, set it to `true` to
    # enable debug logging.
    # NOTE(prozlach): From what I noticed, if the tests do not finish within 45
    # minutes, they will not finish in 60 minutes either. A lot depends on the
    # latency between the Gitlab runner and azure store account. Moving Azure
    # storage closer to Gitlab runners (i.e. us-east Azure zone) decreased run
    # time from ~40m to around 9m. 
  tags:
    # NOTE(prozlach): run on a custom runner, that runs on Azure VM which has
    # managed credentials set up for the storage account and container that CI
    # variables define.
    - azure-managed_identity_auth
  script:
    # NOTE(prozlach): we need to make sure that Azure SDK will not try to auth
    # with creds from environment and instead tries to obtain managed
    # credentials from the VM itself.
    - |
      unset AZURE_ACCOUNT_KEY
      unset AZURE_TENANT_ID
      unset AZURE_CLIENT_ID
      unset AZURE_CLIENT_SECRET
      $GO_TEST -timeout=$TEST_TIMEOUT -v -coverprofile=coverage.out -tags=$BUILDTAGS $PACKAGE
  # TODO: remove allow_failure once the test setup is fixed
  # https://gitlab.com/gitlab-org/container-registry/-/issues/1478
  allow_failure: true

api:
  extends: .go-version-matrix
  stage: integration
  variables:
    TAGS: 'integration,handlers_test'
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS

api:conformance:
  extends: .go-version-matrix
  stage: integration
  variables:
    TAGS: 'integration,api_conformance_test'
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS

.database: &database
  extends:
    - .go-test
    - .go-pg-version-matrix
  stage: integration
  variables: &database-variables
    FF_NETWORK_PER_BUILD: 1
    POSTGRES_PASSWORD: "secret"
    POSTGRES_DB: "registry_test"
    REGISTRY_DATABASE_ENABLED: "true"
    REGISTRY_DATABASE_HOST: "db"
    REGISTRY_DATABASE_PORT: "5432"
    REGISTRY_DATABASE_USER: "postgres"
    REGISTRY_DATABASE_PASSWORD: "secret"
    REGISTRY_DATABASE_DBNAME: "registry_test"
    REGISTRY_DATABASE_SSLMODE: "disable"
    TAGS: 'integration'
  services:
    - name: postgres:${PG_VERSION}-alpine
      alias: "db"
  script: $GO_TEST -v -timeout=25m -coverprofile=coverage.out -tags=$TAGS

api:online-gc:
  <<: *database
  variables:
    <<: *database-variables
    TAGS: 'integration,online_gc_test'
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS -run=OnlineGC

database:migrations:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/datastore/migrations'

database:datastore:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/datastore'

database:api:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TAGS: integration,handlers_test

database:api-conformance:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TAGS: 'integration,api_conformance_test'
  script: $GO_TEST -v -timeout=25m -tags=$TAGS

database:api-gitlab:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TAGS: 'integration,api_gitlab_test'
  script: $GO_TEST -v -timeout=25m -tags=$TAGS

# Tests that simulate adverse network conditions/errors between the registry and its database.
database:api-fault-tolerance:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/handlers'
    TOXIPROXY_HOST: 'toxiproxy'
    TOXIPROXY_PORT: '8474'
    TAGS: 'integration,toxiproxy'
  services:
    # `services` are not extended, so we have to redeclare `postgres` here.
    - name: postgres:${PG_VERSION}-alpine
      alias: "db"
    - name: shopify/toxiproxy
      alias: "toxiproxy"
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS -run ^TestDBFaultTolerance

database:background-migrations:
  <<: *database
  variables:
    <<: *database-variables
    PACKAGE: 'github.com/docker/distribution/registry/bbm'
    TAGS: 'integration'
  script: $GO_TEST -v -coverprofile=coverage.out -tags=$TAGS

.database-load-balancing: &database-load-balancing
  <<: *database
  variables: &database-load-balancing-variables
    <<: *database-variables
    POSTGRESQL_PASSWORD: "secret"
    POSTGRESQL_DATABASE: "registry_test"
    POSTGRESQL_REPLICATION_USER: "repluser"
    POSTGRESQL_REPLICATION_PASSWORD: "replpassword"
    POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    REGISTRY_DATABASE_HOST: "primary"
    REGISTRY_DATABASE_LOADBALANCING_ENABLED: "true"
    REGISTRY_REDIS_CACHE_ENABLED:  "true"
    REGISTRY_REDIS_CACHE_ADDR: "redis:6379"
    PACKAGE: "github.com/docker/distribution/registry/handlers"
    TAGS: "integration,handlers_test,api_gitlab_test,api_conformance_test"
  services:
    - name: redis:alpine
      alias: "redis"
    - name: bitnami/postgresql:${PG_VERSION}
      alias: "primary"
      variables:
        POSTGRESQL_REPLICATION_MODE: "master"
        POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    - name: bitnami/postgresql:${PG_VERSION}
      alias: "replica1"
      variables:
        POSTGRESQL_REPLICATION_MODE: "slave"
        POSTGRESQL_MASTER_HOST: "primary"
        POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    - name: bitnami/postgresql:${PG_VERSION}
      alias: "replica2"
      variables:
        POSTGRESQL_REPLICATION_MODE: "slave"
        POSTGRESQL_MASTER_HOST: "primary"
        POSTGRESQL_REPLICATION_USE_PASSFILE: "false"
    # not needed for all scenarios but avoids having to declare all services in each as `services` can't be extended
    - name: registry.gitlab.com/gitlab-org/container-registry/test-dns-server:28d4a455
      alias: "test-dns-server"
      variables:
        DNS_SERVER_SRV_RECORD: "replica.registry-db.service.consul"
        DNS_SERVER_REPLY_HOSTS: "replica1,replica2"
        DNS_SERVER_REPLY_PORT: "5432"
        DNS_SERVER_LISTEN_PORT: "8600"
  script: $GO_TEST -v -timeout=35m -coverprofile=coverage.out -tags=$TAGS

database:api-load-balancing-hosts:
  <<: *database-load-balancing
  variables:
    <<: *database-load-balancing-variables
    REGISTRY_DATABASE_LOADBALANCING_HOSTS: "replica1,replica2"

database:api-load-balancing-discovery:
  <<: *database-load-balancing
  variables:
    <<: *database-load-balancing-variables
    REGISTRY_DATABASE_LOADBALANCING_RECORD: "replica.registry-db.service.consul"
    REGISTRY_DATABASE_LOADBALANCING_NAMESERVER: "test-dns-server"
    REGISTRY_DATABASE_LOADBALANCING_PORT: "8600"

.cache:redis: &cache-redis
  extends: .go-version-matrix
  stage: integration
  variables: &cache-redis-variables
    REDIS_ADDR: "redis:6379"
    PACKAGE: "github.com/docker/distribution/registry/storage/cache/redis"
  services:
    - name: redis:alpine
      alias: "redis"
  script: $GO_TEST -v -coverprofile=coverage.out -tags=integration

cache:redis:
  extends: .cache:redis

cache:redis-auth:
  <<: *cache-redis
  variables:
    <<: *cache-redis-variables
    # create a Docker network per build so that services can talk with each other
    FF_NETWORK_PER_BUILD: 1
    REDIS_USERNAME: "my-redis-user"
    REDIS_PASSWORD: "my-redis-pass"
  services:
    - name: redis:alpine
      alias: "redis"
      command:
        - /bin/sh
        - -c
        - |
          echo "Starting Redis..."
          cat <<EOF > /etc/redis.conf
          user default off
          user ${REDIS_USERNAME} on >${REDIS_PASSWORD} allcommands allkeys
          EOF
          redis-server /etc/redis.conf

cache:redis-sentinel:
  <<: *cache-redis
  variables:
    <<: *cache-redis-variables
    # create a Docker network per build so that services can talk with each other
    FF_NETWORK_PER_BUILD: 1
    # config for redis-sentinel
    REDIS_MASTER_HOST: "redis"
    REDIS_MASTER_SET: "main-redis"
    # config for app
    REDIS_ADDR: "redis-sentinel:26379"
    REDIS_MAIN_NAME: "main-redis"
  services:
    - name: redis:alpine
      alias: "redis"
    - name: bitnami/redis-sentinel
      alias: "redis-sentinel"

cache:redis-sentinel-auth:
  <<: *cache-redis
  variables:
    <<: *cache-redis-variables
    # create a Docker network per build so that services can talk with each other
    FF_NETWORK_PER_BUILD: 1
    # config for redis-sentinel
    REDIS_MASTER_HOST: "redis"
    REDIS_MASTER_SET: "main-redis"
    # config for app
    REDIS_ADDR: "redis-sentinel:26379"
    REDIS_MAIN_NAME: "main-redis"
    REDIS_SENTINEL_USERNAME: "my-sentinel-user"
    REDIS_SENTINEL_PASSWORD: "my-sentinel-pass"
  services:
    - name: redis:alpine
      alias: "redis"
    - name: bitnami/redis-sentinel
      alias: "redis-sentinel"
      command:
        - /bin/sh
        - -c
        - |
          echo "Starting Redis Sentinel..."
          cat <<EOF > /opt/bitnami/redis-sentinel/etc/sentinel.conf
          user default off
          user ${REDIS_SENTINEL_USERNAME} on >${REDIS_SENTINEL_PASSWORD} +@all
          sentinel monitor ${REDIS_MAIN_NAME} ${REDIS_MASTER_HOST} 6379 2
          sentinel resolve-hostnames yes
          EOF
          redis-sentinel /opt/bitnami/redis-sentinel/etc/sentinel.conf

base-driver:
  <<: *storage-driver-test
  variables:
    <<: *storage-driver-variables
    PACKAGE: "github.com/docker/distribution/registry/storage/driver/base"
